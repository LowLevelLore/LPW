{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PER_STEP_REWARD = -1\n",
    "ENV_DYNAMICS_PROB = 1\n",
    "POLICY_PROB = 0.25\n",
    "GAMMA = 0.9\n",
    "EPSILON = 0.000001\n",
    "IS_DETERMINISTIC = True\n",
    "GRID_DIM = 4\n",
    "\n",
    "GOAL_STATES = [(0, 0), (3, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord2state = {}\n",
    "state2coord = {}\n",
    "\n",
    "st = 0\n",
    "for i in range(GRID_DIM):\n",
    "    for j in range(GRID_DIM):\n",
    "        coord2state[(i, j)] = st\n",
    "        state2coord[st] = (i, j)\n",
    "        st += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (0, 0), 1: (0, 1), 2: (0, 2), 3: (0, 3), 4: (1, 0), 5: (1, 1), 6: (1, 2), 7: (1, 3), 8: (2, 0), 9: (2, 1), 10: (2, 2), 11: (2, 3), 12: (3, 0), 13: (3, 1), 14: (3, 2), 15: (3, 3)}\n",
      "{(0, 0): 0, (0, 1): 1, (0, 2): 2, (0, 3): 3, (1, 0): 4, (1, 1): 5, (1, 2): 6, (1, 3): 7, (2, 0): 8, (2, 1): 9, (2, 2): 10, (2, 3): 11, (3, 0): 12, (3, 1): 13, (3, 2): 14, (3, 3): 15}\n",
      "[0, 15]\n"
     ]
    }
   ],
   "source": [
    "print(state2coord)\n",
    "print(coord2state)\n",
    "\n",
    "GOAL_STATES_MAPPED = list(map(lambda x: coord2state[x], GOAL_STATES))\n",
    "print(GOAL_STATES_MAPPED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = np.zeros(len(state2coord), dtype=np.float64)\n",
    "\n",
    "for state in GOAL_STATES_MAPPED:\n",
    "    state_values[state] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    Up = (0, -1)\n",
    "    Down = (0, 1)\n",
    "    Left = (-1, 0)\n",
    "    Right = (1, 0)\n",
    "    \n",
    "    def all_actions():\n",
    "        return (Actions.Up, Actions.Down, Actions.Left, Actions.Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_action(action: Actions, state: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    return (max(0, min(action.value[0] + state[0], GRID_DIM - 1)), max(0, min(action.value[1] + state[1], GRID_DIM - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diff = 0\n",
    "\n",
    "while True:\n",
    "    last_state_values = state_values.copy()\n",
    "    max_diff = 0\n",
    "\n",
    "    for i in range(GRID_DIM):\n",
    "        for j in range(GRID_DIM):\n",
    "            current_state = coord2state[(i, j)]\n",
    "            if current_state in GOAL_STATES_MAPPED:\n",
    "                continue\n",
    "\n",
    "            best_value = -float('inf')\n",
    "            for action in Actions.all_actions():\n",
    "                next_state = coord2state[apply_action(action, state2coord[current_state])]\n",
    "                value = POLICY_PROB * (PER_STEP_REWARD + GAMMA * last_state_values[next_state])\n",
    "                best_value = max(best_value, value)\n",
    "\n",
    "            state_values[current_state] = best_value\n",
    "            max_diff = max(max_diff, abs(state_values[current_state] - last_state_values[current_state]))\n",
    "\n",
    "    if max_diff < EPSILON:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.25       -0.30625    -0.31890625]\n",
      " [-0.25       -0.30625    -0.31890625 -0.30625   ]\n",
      " [-0.30625    -0.31890625 -0.30625    -0.25      ]\n",
      " [-0.31890625 -0.30625    -0.25        0.        ]]\n"
     ]
    }
   ],
   "source": [
    "state_values = np.array(state_values, dtype=np.float64).reshape((GRID_DIM, GRID_DIM))\n",
    "print(state_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
