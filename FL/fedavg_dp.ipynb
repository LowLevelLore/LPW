{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.input_layer = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3) # 28*28*1 -> 26*26*4\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2) \n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(in_features=11*11*16, out_features=512)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.output = nn.Linear(in_features=512, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pooling(self.activation(self.input_layer(x))) # 28 * 28 * 1 -> 26 * 26 * 4 -> 13 * 13 * 4\n",
    "        x = self.activation(self.conv(x)) # 13 * 13 * 4 -> 11 * 11 * 16\n",
    "        return self.output(self.dropout(self.linear(self.flatten(x)))) # 11 * 11 * 16 -> 512 -> 10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def client_update(model, train_loader, epochs=1, lr=0.01):\n",
    "    model = copy.deepcopy(model)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(w_list):\n",
    "    avg_w = copy.deepcopy(w_list[0])\n",
    "    for key in avg_w.keys():\n",
    "        for i in range(1, len(w_list)):\n",
    "            avg_w[key] += w_list[i][key]\n",
    "        avg_w[key] = torch.div(avg_w[key], len(w_list))\n",
    "    return avg_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = SampleNet()\n",
    "num_rounds = 10\n",
    "num_clients = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "client_data_indices = np.array_split(np.arange(len(mnist_data)), 3)\n",
    "client_loaders = [DataLoader(Subset(mnist_data, idx), batch_size=32, shuffle=True) for idx in client_data_indices]\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 1 ---\n",
      "Global Test Accuracy: 88.74%\n",
      "\n",
      "--- Round 2 ---\n",
      "Global Test Accuracy: 91.14%\n",
      "\n",
      "--- Round 3 ---\n",
      "Global Test Accuracy: 92.09%\n",
      "\n",
      "--- Round 4 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m client_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_clients):\n\u001b[32m      8\u001b[39m     client_model = copy.deepcopy(global_model)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     local_w = \u001b[43mclient_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     noisy_weights = {}\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m local_w.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mclient_update\u001b[39m\u001b[34m(model, train_loader, epochs, lr)\u001b[39m\n\u001b[32m     24\u001b[39m         loss = loss_fn(output, target)\n\u001b[32m     25\u001b[39m         loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model.state_dict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/optim/optimizer.py:89\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m prev_grad = torch.is_grad_enabled()\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Note on graph break below:\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# we need to graph break to ensure that aot respects the no_grad annotation.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# graph break to allow the fully fused fwd-bwd-optimizer graph to be compiled.\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# see https://github.com/pytorch/pytorch/issues/104053\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m     91\u001b[39m     ret = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/grad_mode.py:187\u001b[39m, in \u001b[36mset_grad_enabled.__init__\u001b[39m\u001b[34m(self, mode)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = torch.is_grad_enabled()\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m.mode = mode\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_set_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "NOISE_SCALE = 0.01\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    print(f\"\\n--- Round {round+1} ---\")\n",
    "    local_weights = []\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "        local_w = client_update(client_model, client_loaders[client_id], epochs=1)\n",
    "        \n",
    "        noisy_weights = {}\n",
    "        for key, value in local_w.items():\n",
    "            noisy_weights[key] = value + NOISE_SCALE * torch.empty(value.shape).normal_(mean=0, std=0.01)\n",
    "            \n",
    "        local_weights.append(noisy_weights)\n",
    "\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    acc = evaluate_model(global_model, test_loader)\n",
    "    print(f\"Global Test Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
